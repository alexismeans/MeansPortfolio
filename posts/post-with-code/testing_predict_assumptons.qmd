---
title: "Checking Biomass Predictions"
author: "Alexis Means"
date: "2025-10-2"
description: This document contains assumption tests and plots to analyze my linear regression equations for biomass predictions. 
format:
  html:
    toc: true
    toc-location: left
    toc-depth: 3
editor: visual
code-fold: true
execute: 
  warning: false
  message: false
---

```{r}
spp_model <- readRDS("C:/Users/Alexis Means/Documents/Project/Nutrition Sampling/R code/biomass/regression_equations/24and25-Biomass-Regression-Species-Top-Model-List.rds")

fam_model <- readRDS("C:/Users/Alexis Means/Documents/Project/Nutrition Sampling/R code/biomass/regression_equations/24and25-Biomass-Regression-Family-Top-Model-List.rds")

genus_model <- readRDS("C:/Users/Alexis Means/Documents/Project/Nutrition Sampling/R code/biomass/regression_equations/24and25-Biomass-Regression-Genus-Top-Model-List.rds")

fg_model <- readRDS("C:/Users/Alexis Means/Documents/Project/Nutrition Sampling/R code/biomass/regression_equations/24and25-Biomass-Regression-Functional-Group-Top-Model-List.rds")

all_models <- list(
  spp   = spp_model,
  fam   = fam_model,
  genus = genus_model,
  fg    = fg_model
)

```

## R-squared, AIC and Coefficients Values

Here are the updated R-squared and AIC values of the new regression equations that include an interaction term between various transformations of Julian Day and Percent cover. Ryan helped me code the interaction term into the dredging model, so every combination should have been considered. I currently have it displaying the top three models for each species, genus etc because the highest R-squared value did not necessarily always equal the lowest AIC. I wanted to keep them just as a comparison. To actually run the predictions, I used whichever equation had the best R-squared value.

A lot of the species level regressions look pretty good and I believe are the main source of prediction. There are still a few that do not meet the R-squared cutoff of 0.6. As you move up through the hierarchy of regression equations they progressively get worse. I am not sure what to do next to improve them. Or if it is worth working to improve them rather than just resulting in using the functional group like Katey did. However, most of the functional group regression equations currently have the worst R-squared values. Ryan Martin suggested potentially recategorizing my functional groups to reflect the size of the plants observed (e.g. short forb vs tall forb instead of annual vs perennial)

### Species Level Regressions

```{r}
#| warning: FALSE
library(tidyverse)
library(readr)
library(readxl)
library(DT)

spp <- "C:/Users/Alexis Means/Documents/Project/Nutrition Sampling/R code/biomass/processed.data/spp_models_diagnostics.xlsx"

spp_predictions <- read_excel(spp, "Sheet1")

datatable(spp_predictions, options = list(pageLength = 10))
```

### Genus Level Regressions

```{r}
genus <- "C:/Users/Alexis Means/Documents/Project/Nutrition Sampling/R code/biomass/processed.data/genus_models_diagnostics.xlsx"

genus_predictions <- read_excel(genus, "Sheet1")

datatable(genus_predictions, options = list(pageLength = 10))

```

### Family Level Regressions

```{r}
fam <- "C:/Users/Alexis Means/Documents/Project/Nutrition Sampling/R code/biomass/processed.data/family_models_diagnostics.xlsx"

fam_predictions <- read_excel(fam, "Sheet1")

datatable(fam_predictions, options = list(pageLength = 10))
```

### Functional Group Regressions

```{r}
fg <- "C:/Users/Alexis Means/Documents/Project/Nutrition Sampling/R code/biomass/processed.data/fg_models_diagnostics.xlsx"

fg_predictions <- read_excel(fg, "Sheet1")

datatable(fg_predictions, options = list(pageLength = 10))
```

## Predicted Biomass Values

After including the interaction term between Julian Day and Percent cover in my linear regression models, here are the new predicted biomass outputs. I included a column that references which regression equation was used to predict the biomass. If the none of the regressions were above an R-squared value of 0.6 I had it fall back to use which ever equation had the highest value (typically the species regression). Relatively they are starting to look better, but there are still a lot of predicted zeros. The end of this documents includes scatterplots to better compare the predicted vs observed biomass values for each species.

These predictions do not include any of the species that were observed as 1% of cover in \>80% of the quadrats that the species was observed. I removed those to both create the linear regression equations as well as before predicting biomass for the remaining species. I followed Katey's procedure and predicted the biomass for those 1% species by taking the mean of the measured biomass values and upscaling it when needed.

```{r}
#|warning: FALSE
df <- "C:/Users/Alexis Means/Documents/Project/Nutrition Sampling/R code/biomass/24and25predictions.xlsx"

predictions <- read_excel(df, "Sheet1")

pred <- predictions %>% 
  select(ID, Spp, pred_DryWeight, Percent, pred_source)

datatable(pred, options = list(pageLength = 10))
```

## Regression Equations Used

```{r}
# ---- Helper function to pick best model per group ----
select_best_models <- function(model_list) {
  model_info <- tibble(
    model_name = names(model_list),
    base_name = str_remove(model_name, "\\d+$"),  # remove trailing digits
    r2 = map_dbl(model_list, ~ summary(.x)$r.squared)
  )
  
  best_models <- model_info %>%
    group_by(base_name) %>%
    slice_max(order_by = r2, n = 1, with_ties = FALSE) %>%
    ungroup()
  
  selected <- model_list[best_models$model_name]
  names(selected) <- best_models$base_name
  return(selected)
}

# ---- Apply to each list ----
spp_model_best   <- select_best_models(spp_model)
fam_model_best   <- select_best_models(fam_model)
genus_model_best <- select_best_models(genus_model)
fg_model_best    <- select_best_models(fg_model)

# ---- Combine into one master list ----
all_models_best <- list(
  spp   = spp_model_best,
  fam   = fam_model_best,
  genus = genus_model_best,
  fg    = fg_model_best
)

# Function to display all model formulas and R² for a given list
print_all_models <- function(model_list, level_name) {
  cat("\n==============================\n")
  cat("=== ", toupper(level_name), " MODELS ===\n")
  cat("==============================\n")
  
  for (nm in names(model_list)) {
    mod <- model_list[[nm]]
    r2  <- summary(mod)$r.squared
    cat("\n", nm, "\n")
    print(formula(mod))
    cat("R² =", round(r2, 3), "\n")
  }
}

# Run for each level
print_all_models(spp_model_best, "species")
print_all_models(fam_model_best, "family")
print_all_models(genus_model_best, "genus")
print_all_models(fg_model_best, "functional group")


```

## Scatterplots of Predicted vs Observed Biomass

Sorry in advance for the extensive amounts of scatterplots below. I plotted the biomass measurement based on observation ID as well as Percent cover in order to compare the predicted vs observed biomass values. The plot with the observation ID is meant more to flag any points that I may need to remove in order to help the predictions.

```{r}
#|warning: False
#|Message: False

library(ggplot2)
library(dplyr)
library(purrr)
library(glue) 
library(patchwork)  # for combining plots side by side

plot_species_predictions <- function(species_name, predictions, save_plots = FALSE) {
  
  # Filter for this species
  dat <- predictions %>% filter(Spp == species_name)
  
  # Prepare annotation text
  formula_text <- unique(dat$Formula[dat$source_group == "Predicted"])
  r2_text <- unique(dat$R2[dat$source_group == "Predicted"])
  pred_source_text <- unique(dat$pred_source[dat$source_group == "Predicted"])
  
  annotation_text <- if (length(formula_text) > 0) {
    glue("Source: {pred_source_text}\n{formula_text}\nR² = {r2_text}")
  } else {
    ""
  }
  
  # Base theme
  base_theme <- theme_bw(base_size = 12) +
    theme(
      legend.title = element_blank(),
      plot.subtitle = element_text(size = 10, face = "italic")
    )
  
  # Plot 1: pred_DryWeight vs Percent
  p1 <- ggplot(dat, aes(x = Percent, y = pred_DryWeight, color = source_group)) +
    geom_point(size = 2, alpha = 0.8) +
    labs(
      title = glue("{species_name} — Predicted Dry Weight"),
      subtitle = annotation_text,
      x = "Percent Cover",
      y = "Predicted Dry Weight (g)"
    ) +
    base_theme
  
  # Plot 2: pred_DryWeight vs ID
  p2 <- ggplot(dat, aes(x = ID, y = pred_DryWeight, color = source_group)) +
    geom_point(size = 2, alpha = 0.8) +
    labs(
      x = "Observation ID",
      y = "Predicted Dry Weight (g)"
    ) +
    base_theme
  
  # Combine plots side by side with legend at bottom
  combined_plot <- p1 + p2 + 
    plot_layout(guides = "collect") & 
    theme(legend.position = "bottom", legend.direction = "horizontal")
  
  # Save or display
  if (save_plots) {
    ggsave(glue("plots/{species_name}_pred_plot.png"), combined_plot, width = 10, height = 5, dpi = 300)
  } else {
    print(combined_plot)
  }
}

# Run for all species
species_list <- unique(predictions$Spp)
walk(species_list, ~plot_species_predictions(.x, predictions))
```

## Questions?

-   I think this is starting to look really good, but there are a handful of predicted zeros that I am still not sure what do to. A lot of them look like they are for 1% cover, so that is not as concerning, but there are a few that have upwards of 25 percent cover and it is still predicting a biomass weight of 0.

-   There are 3 or 4 species that I don't have any regression equation for (the blanks in the predictions) because there was not enough of them observed even within the functional group to predict. I am not sure what to do with those observations.

-   Is it worth restructuring my functional groups (into tall and short) and seeing if that improves some of the predictions

-   I believe Ryan Martin mentioned that the scatterplots may be useful to identify points that could be throwing off the regressions. I don't know how extreme a point would need to be before removing it.
